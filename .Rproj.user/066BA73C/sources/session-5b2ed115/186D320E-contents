---
title: "Setup & Dataset"
---

## Requirements

### Environment

For this workshop we will be using R (4.4.1 or above) and RStudio (2024.04.2+764 or above).

### Packages \<!--# #Check all against the new version of the worksheet

### replace many with [Spacyr](https://cran.r-project.org/web/packages/spacyr/vignettes/using_spacyr.html)?--\>

\*\*Missing PART OF SPEECH package\*\*

**spacyr** provides a convenient R wrapper around the Python [spaCy](https://spacy.io/) package. It offers easy access to the following functionality of spaCy:

-   parsing texts into tokens or sentences;

-   lemmatizing tokens;

-   parsing dependencies (to identify the grammatical structure of the sentence); and

-   identifying, extracting, or consolidating token sequences that form named entities or noun phrases.

This workshop requires several packages to assist us with the tasks categorized below.

*Data Import & Preparation*

-   **`readr`**: Reads CSV and text files into R for processing.

-   **`dplyr`**: Used to clean, filter, and manipulate textual datasets.

-   **`tidyverse`**: A collection of core packages for data wrangling, including `dplyr`, `ggplot2`, `readr`, and more.

*Text Cleaning & Preprocessing*

-   **`textclean`**: Cleans and standardizes raw text (e.g., removes special characters, fixes typos).

-   **`tm`**: **A full framework for text mining, including preprocessing steps like stopword removal and document-term matrix creation. #check if indeed needed**

-   **`stopwords`**: Provides lists of stop words for various languages to remove uninformative words.

-   **`stringr`**: Performs string operations such as pattern matching and substitution.

*Tokenization & Lexical Processing*

-   **`tidytext`**: Converts text into tidy data frames for tokenization and sentiment scoring.

-   **`textdata`**: Supplies pre-built sentiment lexicons for use with `tidytext` or `syuzhet`.

*Sentiment & Emotion Analysis*

-   **`syuzhet`**: Performs sentiment and emotion classification using lexicons. <!--# change to sentimentr instead - more robust -->

-   **`emoji`**: Adds emoji symbols to datasets for use in sentiment/emotion analysis involving visual or symbolic content.

*Visualization*

-   **`ggplot2`**: visualizes sentiment trends, word frequencies, and other metrics using customizable plots.

-   **`emojifont`**: Adds emojis to plots for a visual representation of emotional tone.

-   **`RColorBrewer`**: Provides color palettes for enhancing the clarity and appeal of sentiment visualizations.

*Package Management & Development*

-   **`devtools`**: Enables installation of development versions of packages (e.g., from GitHub) and simplifies package management.

    ::: callout-important
    ## üì¶ Installing & Loading Packages

    The code to install and load the required packages is included in the `sentiment-analysis.qmd` worksheet.
    :::

## Project File & Sample Data

Our running example draws on publicly available data from profiles on X (formerly Twitter). Specifically, we collected all posts from the first and second days following the season finales of both Season 1 and Season 2 of the Apple TV series \[*Severance*\](https://en.wikipedia.org/wiki/Severance\_(TV_series).

The data was obtained using Brandwatch, a social media analytics platform subscribed by the UCSB Library [(learn more)](https://www.library.ucsb.edu/dreamlab/brandwatch).

Our search query was carefully constructed to capture relevant posts about the television series Severance, while filtering out unrelated content. We used a combination of keywords to include relevant mentions and exclusion strategies to eliminate noise.

Our inclusion criteria included "severance" (in any capitalization), and at least one term related to the show, such as: "series", "show", "AppleTV", "AppleTV+", "Apple", "season". To avoid unrelated results‚Äîparticularly those referring to employment severance‚Äîwe excluded posts that mentioned: "package", "benefits", "layoff", "Cigna" and, "executive"; terms are commonly associated with corporate severance packages.

![*Query Used for Retrieving Relevant Posts in Brandwatch*](images/query.png)

We compiled two datasets: one from April 8‚Äì10, 2022, capturing impressions from Season 1 finale, and another from March 20‚Äì22, 2025, following the Season 2 finale. In total, the dataset contains 1,786 posts for 2022 and 4,091 for 2025.

To ensure compliance with [GDPR regulations](https://gdpr-info.eu), and to avoid the inadvertent release of sensitive information, we consolidated the raw data to include only two columns: a unique post ID and the content of the message. The final dataset is publicly available

Whether you're a longtime fan of the show or encountering it for the first time, this example offers a valuable case study in analyzing sentiment in unstructured public opinion data. Because data was pulled from social media it also serves as a guideline for examining more challenging text corpora, due to informal language, use of slang, emojis, hashtags, and abbreviations, as well as their variable length, inconsistent formatting, and inclusion of multimedia elements like images, videos, and links.

This lesson is supplemented by a [Quarto project](https://quarto.org/docs/projects/quarto-projects.html), containing: 1) `sentiment-analysis.qmd` that we will be using as the workshop worksheet, 2) two data files with the text we will analyze `season1-comments.csv` and `season2-comments.csv`.

::: callout-important
# ‚§µÔ∏è Download & Save Project File

Access <add Zenodo Link when ready>, ensure to download it, and save in an easy to locate place (e.g., Desktop).
:::
