---
title: "Setup & Dataset"
---

## System Requirements

### Environment

For this workshop we will be using R (4.4.1 or above) and RStudio (2024.04.2+764 or above).

### Packages

This workshop requires several packages (listed in alphabetical order) to assist us with the tasks categorized below:

-   [`emoji`](https://cran.r-project.org/package=emoji): Provides functions for converting text to emoji and vice versa, useful in text mining and social media analysis.

-   [`ggplot2`](https://cran.r-project.org/package=ggplot2): A powerful data visualization package based on the Grammar of Graphics, part of the tidyverse.

-   [`lexicon`](https://cran.r-project.org/package=lexicon): Offers sentiment lexicons, stopword lists, and other text data dictionaries for NLP and text mining tasks.

-   [`sentimentr`](https://cran.r-project.org/package=sentimentr): Calculates sentiment scores by considering sentence structure, valence shifters, and negations.

-   [`stopwords`](https://cran.r-project.org/package=stopwords): Provides multilingual stopword lists for text preprocessing in NLP pipelines.

-   [`stringi`](https://cran.r-project.org/package=stringi): A comprehensive string processing package supporting Unicode and locale-aware operations.

-   [`syuzhet`](https://cran.r-project.org/package=syuzhet): Extracts sentiment and emotion from text using lexicon-based methods, including NRC emotion lexicon for more fine-grained emotion analysis.

-   [`textclean`](https://cran.r-project.org/package=textclean): Cleans and normalizes text data (e.g., expanding contractions, handling misspellings, and replacing characters).

-   [`textstem`](https://cran.r-project.org/package=textstem): Performs text stemming and lemmatization for natural language processing.

-   [`tidyr`](https://cran.r-project.org/package=tidyr): Provides tools for tidying data, including reshaping, pivoting, and separating columns.

-   [`tidytext`](https://cran.r-project.org/package=tidytext): Enables text mining using tidy data principles, including tokenization and binding with tidyverse workflows.

-   [`tidyverse`](https://cran.r-project.org/package=tidyverse): A collection of R packages (including dplyr, tidyr, ggplot2, readr, etc.) designed for data science workflows.

::: {.callout-note appearance="minimal" icon="false"}
## üì¶ Installing & Loading Packages

The code to install and load the required packages is included in the `worksheet.qmd`. However, we will be installing them via the console for one-time setup.
:::

## Project File & Sample Data

The running example draws on publicly available data from profiles on X (formerly Twitter). Specifically, we collected all posts from the first and second days following the season finales of both Season 1 and Season 2 of the Apple TV series [*Severance*](https://en.wikipedia.org/wiki/Severance_(TV_series)).

The data was obtained using Brandwatch, a social media analytics platform subscribed by the UCSB Library [(learn more)](https://www.library.ucsb.edu/dreamlab/brandwatch).

Our search query was carefully constructed to capture relevant posts about the television series Severance, while filtering out unrelated content. We used a combination of keywords to include relevant mentions and exclusion strategies to eliminate noise.

Our inclusion criteria included "severance" (in any capitalization), and at least one term related to the show, such as: "series", "show", "AppleTV", "AppleTV+", "Apple", "season". To avoid unrelated results‚Äîparticularly those referring to employment severance‚Äîwe excluded posts that mentioned: "package", "benefits", "layoff", "Cigna" and, "executive"; terms are commonly associated with corporate severance packages.

![*Query Used for Retrieving Relevant Posts in Brandwatch*](images/query.png)

We compiled two datasets: one from April 8‚Äì10, 2022, capturing impressions from Season 1 finale, and another from March 20‚Äì22, 2025, following the Season 2 finale. In total, the dataset contains 1,786 posts for 2022 and 4,091 for 2025.

Whether you're a longtime fan of the show or encountering it for the first time, this example offers a valuable case study in analyzing sentiment in unstructured public opinion data. Because data was pulled from social media it also serves as a guideline for examining more challenging text corpora, due to informal language, use of slang, emojis, hashtags, and abbreviations, as well as their variable length, inconsistent formatting, and inclusion of multimedia elements like images, videos, and links. Yeah, all the challenges you will face in the "real world" of sentiment analysis of user-generated content.

This lesson is supplemented by a folder, containing two files: 1) `comments.csv` containing the posts we will analyze and their respective ids, and 2) the `worksheet.qmd` where we will be coding, computing, and visualizing the outputs of our tasks.

::: {.callout-important icon="false"}
# ‚§µÔ∏è Download & Save Project File

Download [this folder](https://ucsb.box.com/s/z6buv80wmgqm1wb389o1j6vl9k3ldapv) and save in an easy to locate place (e.g., Desktop).

**\<FIXME: add zenodo doi after run-through\>**
:::
