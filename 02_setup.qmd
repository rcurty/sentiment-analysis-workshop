---
title: "Setup & Dataset"
---

## Requirements

### Environment

For this workshop we will be using R (4.4.1 or above) and RStudio (2024.04.2+764 or above).

### Packages

This workshop requires several packages to assist us with the tasks categorized below:

-   [**emoji**](https://cran.r-project.org/package=emoji): Provides functions for converting text to emoji and vice versa, useful in text mining and social media analysis.

-   [**ggplot2**](https://cran.r-project.org/package=ggplot2): A powerful data visualization package based on the Grammar of Graphics, part of the tidyverse.

-   [**lexicon**](https://cran.r-project.org/package=lexicon): Offers sentiment lexicons, stopword lists, and other text data dictionaries for NLP and text mining tasks.

-   [**sentimentr**](https://cran.r-project.org/package=sentimentr): Calculates sentiment scores by considering sentence structure, valence shifters, and negations.

-   [**stopwords**](https://cran.r-project.org/package=stopwords): Provides multilingual stopword lists for text preprocessing in NLP pipelines.

-   [**stringi**](https://cran.r-project.org/package=stringi): A comprehensive string processing package supporting Unicode and locale-aware operations.

-   [**syuzhet**](https://cran.r-project.org/package=syuzhet): Extracts sentiment and emotion from text using lexicon-based methods, including NRC emotion lexicon for more fine-grained emotion analysis.

-   [**textclean**](https://cran.r-project.org/package=textclean): Cleans and normalizes text data (e.g., expanding contractions, handling misspellings, and replacing characters).

-   [**textstem**](https://cran.r-project.org/package=textstem): Performs text stemming and lemmatization for natural language processing.

-   [**tidyr**](https://cran.r-project.org/package=tidyr): Provides tools for tidying data, including reshaping, pivoting, and separating columns.

-   [**tidytext**](https://cran.r-project.org/package=tidytext): Enables text mining using tidy data principles, including tokenization and binding with tidyverse workflows.

-   [**tidyverse**](https://cran.r-project.org/package=tidyverse): A collection of R packages (including dplyr, tidyr, ggplot2, readr, etc.) designed for data science workflows.\

::: callout-important
## üì¶ Installing & Loading Packages

The code to install and load the required packages is included in the `sentiment-analysis.qmd` worksheet. However, we will be installing them via the console for one-time setup.
:::

## Project File & Sample Data

Our running example draws on publicly available data from profiles on X (formerly Twitter). Specifically, we collected all posts from the first and second days following the season finales of both Season 1 and Season 2 of the Apple TV series \[*Severance*\](https://en.wikipedia.org/wiki/Severance\_(TV_series).

The data was obtained using Brandwatch, a social media analytics platform subscribed by the UCSB Library [(learn more)](https://www.library.ucsb.edu/dreamlab/brandwatch).

Our search query was carefully constructed to capture relevant posts about the television series Severance, while filtering out unrelated content. We used a combination of keywords to include relevant mentions and exclusion strategies to eliminate noise.

Our inclusion criteria included "severance" (in any capitalization), and at least one term related to the show, such as: "series", "show", "AppleTV", "AppleTV+", "Apple", "season". To avoid unrelated results‚Äîparticularly those referring to employment severance‚Äîwe excluded posts that mentioned: "package", "benefits", "layoff", "Cigna" and, "executive"; terms are commonly associated with corporate severance packages.

![*Query Used for Retrieving Relevant Posts in Brandwatch*](images/query.png)

We compiled two datasets: one from April 8‚Äì10, 2022, capturing impressions from Season 1 finale, and another from March 20‚Äì22, 2025, following the Season 2 finale. In total, the dataset contains 1,786 posts for 2022 and 4,091 for 2025.

To ensure compliance with [GDPR regulations](https://gdpr-info.eu), and to avoid the inadvertent release of sensitive information, we consolidated the raw data to include only two columns: a unique post ID and the content of the message. The final dataset is publicly available

Whether you're a longtime fan of the show or encountering it for the first time, this example offers a valuable case study in analyzing sentiment in unstructured public opinion data. Because data was pulled from social media it also serves as a guideline for examining more challenging text corpora, due to informal language, use of slang, emojis, hashtags, and abbreviations, as well as their variable length, inconsistent formatting, and inclusion of multimedia elements like images, videos, and links.

This lesson is supplemented by a [Quarto project](https://quarto.org/docs/projects/quarto-projects.html), containing: 1) `worksheet.qmd` where we will be coding and visualizing the output of our tasks, and 2) a data file containing the posts we will analyze `comments.csv`.

::: callout-important
# ‚§µÔ∏è Download & Save Project File

Access <add Zenodo Link>, ensure to download it, and save in an easy to locate place (e.g., Desktop).
:::
